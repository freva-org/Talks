{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Workshop\n",
    "\n",
    "## Tutorial I: data queries, dataset catalog creation\n",
    "\n",
    "\n",
    "<div style=\"border-left: 4px solid #0366d6; padding: 0.5em; background-color: #deecfc;\">\n",
    "  ℹ️ If you want to know more about these topics please refer to:\n",
    "  <ul>\n",
    "  <li><code>freva-client</code> library <a href='https://example.com' target=\"_blank\">installation</a></li>\n",
    "  <li>Databrowser <a href=\"https://freva-org.github.io/freva-nextgen/databrowser/cli.html\">command line interface </a></li>\n",
    "</ul>  \n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "In this tutorial, we'll learn how to use the `freva-client` library to explore and access available datasets and at the end customize the dataset on Freva to our own liking.\n",
    "\n",
    "First let's see how to install the freva client library:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Client Library\n",
    "\n",
    "| Environment | Installation Command |\n",
    "|-------------|---------------------|\n",
    "| DKRZ/Levante (Recommended) | `$ module load clint gems` |\n",
    "| Conda (Local) | $ `conda create -n freva-client-env -c conda-forge freva-client -y` |\n",
    "| Python (Local) | `$ pip install freva-client` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  border-left: 6px solid rgb(236, 114, 0);\n",
    "  background-color:rgb(253, 231, 157);\n",
    "  color:rgb(19, 19, 18);\n",
    "  padding: 1em;\n",
    "  font-size: 110%;\n",
    "  border-radius: 4px;\n",
    "  margin: 1em 0;\n",
    "\">\n",
    "⚠️ <strong>ATTENTION</strong>: For the Freva Databrowser workshop, please open a Terminal tab in Jupyter and write the following:\n",
    "<pre><code>$ module load clint gems\n",
    "$ da-workshop-setup\n",
    "</code></pre>\n",
    "\n",
    "<br>\n",
    "And then from kernel environment list, please choose, <code>DA Workshop (shell)</code>\n",
    "Now your environment is ready to start!\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let quickly ckeck if `freva-client` is available on our current kernel environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we'll run a simple analysis on the [MPI Grand Ensemble data](https://mpimet.mpg.de/en/research/modeling/grand-ensemble), a large collection of climate simulations. Our goal will be to create an ensemble of global averaged time series of 2 m air temperature.\n",
    "\n",
    "The data browser organizes metadata in a **tree-like hierarchy**. At the top of this structure is the **`project`** facet (equivalent to the **`mip-era`** for CMIP6 Data Reference Syntax) and then it goes down as it follows:\n",
    "```\n",
    ".\n",
    "├── project\n",
    "│   ├── product\n",
    "│   │   ├── institute\n",
    "│   │   │   ├── model\n",
    "│   │   │   │   ├── experiment\n",
    "...\n",
    "```\n",
    "These facets are organised as `{key: value}` pairs. First and foremost, let's find out which search keys are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser data-overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we know that the Grand-Ensemble data is stored under `mpi-ge` but we don't know whether it's under `project` or `product` etc. The databrowser is here to help. You can simply use the `facet` argument to search for all entries containing a certain value, such as `mpi-ge`.\n",
    "\n",
    "Let's get the project(s) of all search keys (or facets) that contain `mpi-ge`.  We can use the `metadata-search` function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser metadata-search --facet mpi-ge --json | jq -rc '.project|join(\", \")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to create a time series of 2 m air temperature we will need to check whether the `tas` (near-surface air temperature) variable is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser metadata-search project=mpi-ge --json | jq -rc '.variable | index(\"tas\") != null'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same vein, let's query the available output time frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser metadata-search project=mpi-ge variable=tas --json | jq -rc \".time_frequency\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let's query the available output experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser metadata-search project=mpi-ge variable=tas time_frequency=mon --time \"2025-01 to 2100-12\" --json | jq -c \".experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do have a rough overview of the available data. We want to cover future scenarios, that is, timesteps from today until 2100. To check how many files were found we can apply the `data-count` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser data-count project=mpi-ge variable=tas time_frequency=mon --time \"2025-01 to 2100-12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back a little bit we see that the `picontrol` experiment _was_ unexpected! Let's check the what is going on. We create a new search and check how many files belong to that search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser data-count project=mpi-ge variable=tas time_frequency=mon experiment=picontrol --time \"2025-01 to 2100-12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the list of file via `data-search`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser data-search project=mpi-ge variable=tas time_frequency=mon experiment=picontrol --time \"2025-01 to 2100-12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a reverse search, that is, check what meta-data is associated with a file, for that we use the `file=` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser metadata-search file=/work/mh1007/CMOR/MPI-GE/output1/MPI-M/MPI-ESM/piControl/mon/atmos/tas/r001i1850p3/v20190123/tas_Amon_MPI-ESM_piControl_r001i1850p3_210001-219912.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't want this pre-industrial control run among our selected datasets we will tell the databrowser to ignore it.\n",
    "\n",
    "We can use the `!` to *not* include a certain value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments=$(freva-client databrowser metadata-search \\\n",
    "  project=mpi-ge \\\n",
    "  variable=tas \\\n",
    "  time_frequency=mon \\\n",
    "  --time=\"2025-01 to 2100-12\" \\\n",
    "  experiment='!picontrol' \\\n",
    "  --json \\\n",
    "  | jq -rc '.experiment | join(\" \")')\n",
    "echo \"$experiments\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to create a global time series for each of the experiments. We can use the search result of the databrowser to directly pip the output into `cdo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir=$(mktemp -d --suffix cdo)\n",
    "for exp in $experiments ;do\n",
    "    outlist=()\n",
    "    # Let's get only the first 5 ensemble member for brevity\n",
    "    members=$(freva-client databrowser metadata-search \\\n",
    "    project=mpi-ge variable=tas time_frequency=mon --time=\"2025-01 to 2100-12\" experiment=\"$exp\" --json |\n",
    "    jq -r '.ensemble | unique | .[:5] | join(\" \")')\n",
    "    for ens in $members;do\n",
    "        echo -ne \"Reading data and calculating TS for experiment $exp in ens: $ens\\r\"\n",
    "        files=$(freva-client databrowser data-search project=mpi-ge variable=tas time_frequency=mon --time=\"2025-01 to 2100-12\" experiment=$exp ensemble=$ens realm=atmos)\n",
    "        outfile=\"$temp_dir/tas_mean_${exp}_${ens}.nc\"\n",
    "        cdo -s fldmean -mergetime $files \"$outfile\"\n",
    "        outlist+=(\"$outfile\")\n",
    "    done\n",
    "    cdo mergetime \"${outlist[@]}\" \"$temp_dir/tas_ensemble_${exp}.nc\"\n",
    "done\n",
    "cdo mergetime $temp_dir/tas_ensemble_*.nc tas_all_experiments.nc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a shallow look at the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdo sinfo tas_all_experiments.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make further analysis with this information, for example, to plot the ensemble spread and mean for each experiment, we would need to need some other specific program, programing language.\n",
    "\n",
    "Please, refer to the python notebook (`Tutorial-py-search-cataloging.ipynb`) for a complete workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset catalogs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've already found our target dataset on Freva, we may want to export the full metadata for other project's partner that might not have direct Freva access or for us to download and access it somewhere else on any other HPC system.\n",
    "\n",
    "In this section we are going to introduce two different types of Catalogues: \n",
    "1. The [**intake-esm**](https://intake-esm.readthedocs.io/en/stable/) catalog provides a lightweight, Python-friendly interface to the metadata of large Earth System Model archives. By pointing to a central JSON index, it lets you discover, filter, and load climate model outputs—such as temperature, precipitation, or ocean variables—without downloading entire datasets. The catalog structure follows the CMIP/ESM conventions, enabling easy subsetting by attributes like project name, variable, experiment, and time period. Once exported as a standalone YAML file, your subsetted catalog can be shared with collaborators who can query and load data locally, with no direct access to the original archive required.\n",
    "\n",
    "\n",
    "2. The [**STAC (SpatioTemporal Asset Catalog)**](https://stacspec.org/en) static catalog defines a simple, filesystem-based layout for geospatial metadata. A static catalog bundles Catalog, Collection, and Item JSON files into a set of directories that mirror your data hierarchy, with no dynamic search API. Bundling the entire catalog into a ZIP archive makes it trivial to distribute or archive a snapshot of your dataset inventory—satellite imagery, climate projections, or any spatiotemporal assets—for offline use, disaster recovery, or reproducible analyses. Once unzipped, the folder structure and JSON files provide the same discovery semantics as a live STAC endpoint.  \n",
    "\n",
    "\n",
    "First, we’ll use **intake-esm** to subset by our chosen search keys-value pairs:  \n",
    "- project: `mpi-ge`\n",
    "- variable: `tas`\n",
    "- time_frequency: `mon`\n",
    "- time: `'2025-01 to 2100-12'`\n",
    "- experiment: `picontrol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser intake-catalogue project=mpi-ge time_frequency=mon variable=tas --time \"2025-01 to 2100-12\" experiment=picontrol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then export the catalogue as e.g. JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser intake-catalogue project=mpi-ge time_frequency=mon variable=tas --time \"2025-01 to 2100-12\" experiment=picontrol > intake_catalog.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We’ll now perform the same operation on a **STAC static catalog**: download the entire catalog as a ZIP archive so you can share or inspect it offline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freva-client databrowser stac-catalogue project=mpi-ge time_frequency=mon variable=tas --time \"2025-01 to 2100-12\" experiment=picontrol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "To complete our explanation about STAC catalog, the **STAC static catalog** is implemented as a set of flat files on a web server or object store (e.g., S3). It exposes the same Item, Catalog, and Collection JSON structure as a dynamic STAC, but without a `/search` endpoint—making it easy to bundle and distribute as a ZIP for disaster recovery or offline use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA Workshop (shell)",
   "language": "bash",
   "name": "da-workshop-shell"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
